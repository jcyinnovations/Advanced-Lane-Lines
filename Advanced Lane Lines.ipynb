{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from CameraOperations import show_grid, correct_distortion, calibrate_camera_from_folder\n",
    "\n",
    "image = mpimg.imread(\"./corrected_images/adj_test4.jpg\")\n",
    "mtx, dist = calibrate_camera_from_folder(\"./camera_cal\",name_pattern=\"calibration*.jpg\", counts=(9,6))\n",
    "un_dst = correct_distortion(image, mtx, dist)\n",
    "show_grid((image, un_dst), (\"Orginal\", \"Corrected for Distortion\"), ticks=(320,80))\n",
    "global_mtx = mtx\n",
    "global_dist = dist\n",
    "global_mtx, global_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from LaneOperations import map_lane_lines\n",
    "from CameraOperations import combined_SR_threshold, perspective_transform, sobel_LR_threshold, sobel_LSR_threshold\n",
    "from ImageProcessing import gaussian_blur\n",
    "from LaneOperations import find_window_centroids, map_lane_lines\n",
    "\n",
    "img_id = \"1189\"\n",
    "image = mpimg.imread(\"./debug_images-project_video/{0}.jpg\".format(img_id))\n",
    "un_dst = correct_distortion(image, global_mtx, global_dist)\n",
    "mapped_lanes, lane_markings, cache = map_lane_lines(un_dst, window_width=40, window_height=48, margin=100)\n",
    "#, DEBUG=True, DEBUG_ID=img_id)\n",
    "show_grid((mapped_lanes, lane_markings), (\"Mapped Lines\", \"Overlaid Image\"), ticks=(80,48))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from CameraOperations import show_grid, correct_distortion, calibrate_camera_from_folder\n",
    "#from LaneOperations import map_lane_lines\n",
    "\n",
    "test_images = os.listdir(\"corrected_images/\")\n",
    "\n",
    "for img in test_images:\n",
    "    image = mpimg.imread('corrected_images/'+img)\n",
    "    mapped_lanes, lane_markings,cache = map_lane_lines(image,window_width=40,window_height=48,margin=60)#,DEBUG=True,DEBUG_ID=img)\n",
    "    show_grid((mapped_lanes, lane_markings), (\"Mapped Lines \"+img, \"Overlaid Image\"), ticks=(160,48))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try it on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "idx=0\n",
    "cache = None\n",
    "def make_frame_lane_markings(image):\n",
    "    global idx\n",
    "    global cache\n",
    "    DEBUG = False\n",
    "    un_dst = correct_distortion(image, global_mtx, global_dist)\n",
    "    mapped_lanes, lane_markings, cache = map_lane_lines(un_dst, window_width=40, window_height=48, margin=60, cache=cache)\n",
    "    if DEBUG:\n",
    "        mpimg.imsave(\"debug_images/{0}_overlay.jpg\".format(idx), lane_markings)\n",
    "        mpimg.imsave(\"debug_images/{0}_mapped_lanes.jpg\".format(idx), mapped_lanes)\n",
    "        mpimg.imsave(\"debug_images/{0}.jpg\".format(idx), image)\n",
    "    idx = idx + 1\n",
    "    return lane_markings\n",
    "\n",
    "clip_output = \"./marked_v4_project_video.mp4\" #\"./marked_v2_harder_challenge_video.mp4\"\n",
    "clip_handle = VideoFileClip(\"project_video.mp4\", audio=False)\n",
    "img_clip = clip_handle.fl_image(make_frame_lane_markings) \n",
    "%time img_clip.write_videofile(clip_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(clip_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying various filters to find the best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from CameraOperations import sobel_threshold, gradient_threshold, sobel_and_gradient, sobel_LSR_threshold, show_grid\n",
    "from CameraOperations import threshold_rgb, threshold_hls\n",
    "from ImageProcessing import image_preprocessing, augment_brightness_camera_images, image_sharpen\n",
    "from LaneOperations import perspective_transform\n",
    "\n",
    "#img_id = 206\n",
    "#image = mpimg.imread(\"./debug_images3/{0}.jpg\".format(img_id))\n",
    "\n",
    "img_id = \"1189\"\n",
    "image = mpimg.imread(\"./debug_images-harder_challenge_video/{0}.jpg\".format(img_id))\n",
    "\n",
    "#image = image_sharpen(image)\n",
    "w = image.shape[1]\n",
    "h = image.shape[0]\n",
    "viewport = [[540,468],[740,468],[1280,720],[0,720]]\n",
    "#viewport = [[round(w/2-105),round(h*.65)],[round(w/2+105),round(h*.65)],[w,h],[0,h]]\n",
    "image = perspective_transform(image, viewport=viewport, offset=0, reverse=False)\n",
    "r = image[:,:,0]\n",
    "hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "s = hls[:,:,2]\n",
    "l = hls[:,:,1]\n",
    "show_grid((r,s,l), (\"Red\", \"Saturation\", \"Luminosity\"))\n",
    "\n",
    "sobel_thresh=(30, 150)\n",
    "gradient_thresh=(0.7, 1.5)\n",
    "sobel_kernel=15\n",
    "s_thresh=(170,240)\n",
    "\n",
    "sobel_r = sobel_threshold(r, orient='y', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "sobel_s = sobel_threshold(s, orient='y', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "sobel_l = sobel_threshold(l, orient='y', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "show_grid((sobel_r,sobel_s,sobel_l), (\"Sobel(Y) Red\", \"Sobel(Y) Saturation\", \"Sobel(Y) Luminosity\"))\n",
    "\n",
    "sobel_r = sobel_threshold(r, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "sobel_s = sobel_threshold(s, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "sobel_l = sobel_threshold(l, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "show_grid((sobel_r,sobel_s,sobel_l), (\"Sobel(X) Red\", \"Sobel(X) Saturation\", \"Sobel(X) Luminosity\"))\n",
    "\n",
    "sobel_r = sobel_threshold(r, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "sobel_s = sobel_threshold(s, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "sobel_l = sobel_threshold(l, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "show_grid((sobel_r,sobel_s,sobel_l), (\"Sobel(Both) Red\", \"Sobel(Both) Saturation\", \"Sobel(Both) Luminosity\"))\n",
    "\n",
    "grad_r = gradient_threshold(r, sobel_kernel=sobel_kernel, thresh=gradient_thresh)\n",
    "grad_l = gradient_threshold(l, sobel_kernel=sobel_kernel, thresh=gradient_thresh)\n",
    "grad_s = gradient_threshold(s, sobel_kernel=sobel_kernel, thresh=gradient_thresh)\n",
    "show_grid((grad_r,grad_s,grad_l), (\"Gradient Red\", \"Gradient Saturation\", \"Gradient Luminosity\"))\n",
    "\n",
    "sg_r = sobel_and_gradient(r, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "sg_l = sobel_and_gradient(l, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "sg_s = sobel_and_gradient(s, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "show_grid((sg_r,sg_s,sg_l), (\"Sobel & Gradient Red\", \"Sobel & Gradient Saturation\", \"Sobel & Gradient Luminosity\"))\n",
    "\n",
    "t_r = threshold_rgb(r, thresh=(190,255))\n",
    "t_l = threshold_hls(l, thresh=(190,255))\n",
    "t_s = threshold_hls(s, thresh=(190,255))\n",
    "show_grid((t_r, t_s, t_l), (\"Threshold Red\", \"Threshold Saturation\", \"Threshold Luminosity\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from CameraOperations import sobel_LR_threshold, sobel_LSR_threshold, combined_SR_threshold\n",
    "from ImageProcessing import gaussian_blur\n",
    "\n",
    "def sobel_LSR_Both_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150)):\n",
    "    r = image[:,:,0]\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l = hls[:,:,1]\n",
    "    s = hls[:,:,2]\n",
    "    sobel_r = sobel_threshold(r, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_l = sobel_threshold(l, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_s = sobel_threshold(s, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    #t_r = threshold_rgb(r, thresh=(220,255))\n",
    "    combined_slr = np.zeros_like(sobel_r)\n",
    "    combined_slr[((sobel_r == 1) | (sobel_l == 1) | (sobel_s == 1))] = 1 # | (t_r == 1)\n",
    "    return combined_slr\n",
    "\n",
    "def sobel_LR_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150)):\n",
    "    r = image[:,:,0]\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l = hls[:,:,1]\n",
    "    s = hls[:,:,2]\n",
    "    sobel_r = sobel_threshold(r, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_l = sobel_threshold(l, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_s = sobel_threshold(s, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    #t_r = threshold_rgb(r, thresh=(220,255))\n",
    "    combined_slr = np.zeros_like(sobel_r)\n",
    "    combined_slr[((sobel_r == 1) | (sobel_l == 1) )] = 1 # | (sobel_s == 1) | (t_r == 1)\n",
    "    return combined_slr\n",
    "\n",
    "sobel_sr = sobel_LSR_Both_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150))\n",
    "sobel_lr = sobel_LR_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150))\n",
    "sobel_slr = sobel_LSR_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150))\n",
    "\n",
    "show_grid((sobel_sr, sobel_lr, sobel_slr), (\"sobel SR (Both)\",\"Sobel LR\", \"sobel LSR (X)\"))\n",
    "show_grid((gaussian_blur(sobel_sr, kernel_size=9), gaussian_blur(sobel_lr, kernel_size=9), gaussian_blur(sobel_slr, kernel_size=9)), (\"sobel SR\",\"Sobel LR\", \"sobel LSR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
