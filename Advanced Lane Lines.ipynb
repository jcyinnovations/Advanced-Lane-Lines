{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from CameraOperations import show_grid, correct_distortion, calibrate_camera_from_folder\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"Calibrating camera on images in camera_cal...\")\n",
    "%time mtx, dist = calibrate_camera_from_folder(\"./camera_cal\",name_pattern=\"calibration*.jpg\", counts=(9,6))\n",
    "print(\"Done Calibrating.\")\n",
    "global_mtx = mtx\n",
    "global_dist = dist\n",
    "\n",
    "print(\"Correcting calibration images...\")\n",
    "test_images = os.listdir(\"camera_cal/\")\n",
    "for img in test_images:\n",
    "    cal_image = mpimg.imread('camera_cal/'+img)\n",
    "    cal_un_dst = correct_distortion(cal_image, global_mtx, global_dist)\n",
    "    mpimg.imsave(\"corrected_images/adj_\"+img, cal_un_dst)\n",
    "\n",
    "# Correct the test images\n",
    "print(\"Correcting test images...\")\n",
    "test_images = os.listdir(\"test_images/\")\n",
    "for img in test_images:\n",
    "    image = mpimg.imread('test_images/'+img)\n",
    "    un_dst = correct_distortion(image, global_mtx, global_dist)\n",
    "    mpimg.imsave(\"corrected_images/adj_\"+img, un_dst)\n",
    "    \n",
    "show_grid((cal_image, cal_un_dst), (\"Orginal\", \"Corrected\"), ticks=(320,80))\n",
    "show_grid((image, un_dst), (\"Test Image\", \"Corrected Test Image\"), ticks=(320,80))\n",
    "#global_mtx, global_dist\n",
    "\n",
    "#Save a dictionary to a pickle file\n",
    "pickle_dict = {'mtx': global_mtx, 'dist': global_dist}\n",
    "pickle.dump(pickle_dict, open(\"./camera_parameters.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image2 = mpimg.imread(\"./camera_cal/calibration2.jpg\")\n",
    "image3 = mpimg.imread(\"./camera_cal/calibration3.jpg\")\n",
    "image2_undst = mpimg.imread(\"./corrected_images/adj_calibration2.jpg\")\n",
    "image3_undst = mpimg.imread(\"./corrected_images/adj_calibration3.jpg\")\n",
    "\n",
    "show_grid((image2, image2_undst), (\"Orginal\", \"Corrected\"), ticks=(320,80))\n",
    "show_grid((image3, image3_undst), (\"Original\", \"Corrected\"), ticks=(320,80))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from CameraOperations import show_grid, correct_distortion, perspective_transform, sobel_LR_threshold\n",
    "from LaneOperations import map_lane_lines\n",
    "from ImageProcessing import image_gradient, image_preprocessing, gaussian_blur, image_sharpen\n",
    "import pickle\n",
    "\n",
    "#Load a pickle file\n",
    "use_dict = True\n",
    "if use_dict:\n",
    "    with open(\"./camera_parameters.p\", mode='rb') as f:\n",
    "        camera_params = pickle.load(f)\n",
    "    global_dist = camera_params['dist']\n",
    "    global_mtx = camera_params['mtx']\n",
    "#viewport = [[540,465],[740,465],[1280,720],[0,720]]   # New Viewport (vanishing point intersection)\n",
    "#viewport = [[560,455],[720,455],[1280,720],[0,720]]   # New Viewport (vanishing point intersection)\n",
    "#viewport = [[565,455],[715,455],[1280,720],[0,720]]   # New Viewport (vanishing point intersection)\n",
    "#viewport = [[488,490],[792,490],[1280,720],[0,720]]   # New Viewport (vanishing point intersection)\n",
    "viewport = [[570,450],[710,450],[1280,720],[0,720]]   # New Viewport (vanishing point intersection)\n",
    "viewport = [[574,450],[706,450],[1280,720],[0,720]]   # New Viewport (vanishing point intersection)\n",
    "offset = 80\n",
    "sobel_thresh=(30, 150)\n",
    "gradient_thresh=(0.7, 1.3)\n",
    "sobel_kernel=15\n",
    "s_thresh=(170,240)\n",
    "\n",
    "#images = glob.glob(\"corrected_images/adj_test*.jpg\")\n",
    "images2 = glob.glob(\"corrected_images/adj_straight*.jpg\")\n",
    "#images = images+images2\n",
    "for img in images2:\n",
    "    image = mpimg.imread(img)\n",
    "    xform = perspective_transform(image, viewport, offset=80)\n",
    "    for k in range(len(viewport)):\n",
    "        x1, y1 = viewport[k][0],viewport[k][1]\n",
    "        x2, y2 = viewport[k-1][0],viewport[k-1][1]\n",
    "        cv2.line(image,(x1,y1),(x2,y2), [255,0,0], 2)\n",
    "    #mapped_lanes, lane_markings,cache = map_lane_lines(image,window_width=50,window_height=80,margin=50) #,DEBUG=True,DEBUG_ID=img)\n",
    "    show_grid((image, xform), (\"Original\",\"Transform\"), ticks=(160,48))\n",
    "    #show_grid((mapped_lanes, lane_markings), (\"Mapped Lanes\", \"Lane Markings\"), ticks=(160,48))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(lane_markings)\n",
    "mpimg.imsave(\"./viewport.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try it on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "idx=0\n",
    "cache = None\n",
    "def make_frame_lane_markings(image):\n",
    "    global idx\n",
    "    global cache\n",
    "    DEBUG = True\n",
    "    un_dst = correct_distortion(image, global_mtx, global_dist)\n",
    "    mapped_lanes, lane_markings, cache = map_lane_lines(un_dst, window_width=40, window_height=48, margin=40, cache=cache)\n",
    "    if DEBUG:\n",
    "        mpimg.imsave(\"debug_images/{0}_overlay.jpg\".format(idx), lane_markings)\n",
    "        mpimg.imsave(\"debug_images/{0}_mapped_lanes.jpg\".format(idx), mapped_lanes)\n",
    "        mpimg.imsave(\"debug_images/{0}.jpg\".format(idx), un_dst)\n",
    "    idx = idx + 1\n",
    "    return lane_markings\n",
    "\n",
    "clip_output = \"./marked_v5_project_video.mp4\" # marked_v4_harder_challenge\n",
    "clip_handle = VideoFileClip(\"project_video.mp4\", audio=False)\n",
    "img_clip = clip_handle.fl_image(make_frame_lane_markings) \n",
    "%time img_clip.write_videofile(clip_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(clip_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying various filters to find the best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from CameraOperations import sobel_threshold, gradient_threshold, sobel_and_gradient, sobel_LSR_threshold, show_grid\n",
    "from CameraOperations import threshold_rgb, threshold_hls, sobel_LR_threshold\n",
    "from ImageProcessing import image_preprocessing, augment_brightness_camera_images, image_sharpen\n",
    "from LaneOperations import perspective_transform\n",
    "\n",
    "#img_id = 206\n",
    "#image = mpimg.imread(\"./debug_images3/{0}.jpg\".format(img_id))\n",
    "\n",
    "img_id = \"1260\"\n",
    "img_id = \"1045\"\n",
    "image = mpimg.imread(\"./debug_images/{0}.jpg\".format(img_id))\n",
    "#image = mpimg.imread(\"signs_vehicles_xygrad.png\")\n",
    "#image = mpimg.imread(\"corrected_images/adj_test4.jpg\")\n",
    "#image = image_sharpen(image)\n",
    "w = image.shape[1]\n",
    "h = image.shape[0]\n",
    "viewport = [[540,465],[740,465],[1280,720],[0,720]]\n",
    "viewport = [[593,449],[691,449],[1080,720],[204,720]]\n",
    "#viewport = [[round(w/2-105),round(h*.65)],[round(w/2+105),round(h*.65)],[w,h],[0,h]]\n",
    "#image = perspective_transform(image, viewport=viewport, offset=0, reverse=False)\n",
    "r = image[:,:,0]\n",
    "hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "s = hls[:,:,2]\n",
    "l = hls[:,:,1]\n",
    "offset=320\n",
    "\n",
    "r_v = perspective_transform(r, viewport=viewport, offset=offset, reverse=False)\n",
    "l_v = perspective_transform(l, viewport=viewport, offset=offset, reverse=False)\n",
    "s_v = perspective_transform(s, viewport=viewport, offset=offset, reverse=False)\n",
    "\n",
    "show_grid((r_v,s_v,l_v), (\"Red\", \"Saturation\", \"Luminosity\"))\n",
    "\n",
    "sobel_thresh=(30, 150)\n",
    "gradient_thresh=(0.7, 1.3)\n",
    "sobel_kernel=15\n",
    "\n",
    "def gradient_threshold2(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    sobelx = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    sobely = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    gradient = np.arctan2(sobely, sobelx)\n",
    "    print(np.min(gradient), np.max(gradient))\n",
    "    sxbinary = np.zeros_like(gradient)\n",
    "    sxbinary[(gradient >= thresh[0]) & (gradient <= thresh[1])] = 1\n",
    "    return sxbinary\n",
    "\n",
    "def sobel_and_gradient2(img, sobel_kernel=3, sobel_thresh=(80, 160), gradient_thresh=(0, np.pi/2)):\n",
    "    gradx = sobel_threshold(img, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    grady = sobel_threshold(img, orient='y', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    mag_binary = sobel_threshold(img, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    dir_binary = gradient_threshold2(img, sobel_kernel=sobel_kernel, thresh=gradient_thresh)\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    return combined\n",
    "\n",
    "DEBUG2 = True\n",
    "if DEBUG2:\n",
    "    sobel_r = sobel_threshold(r, orient='y', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_s = sobel_threshold(s, orient='y', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_l = sobel_threshold(l, orient='y', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_r = perspective_transform(sobel_r, viewport=viewport, offset=offset, reverse=False)\n",
    "    sobel_s = perspective_transform(sobel_s, viewport=viewport, offset=offset, reverse=False)\n",
    "    sobel_l = perspective_transform(sobel_l, viewport=viewport, offset=offset, reverse=False)\n",
    "    show_grid((sobel_r,sobel_s,sobel_l), (\"Sobel(Y) Red\", \"Sobel(Y) Saturation\", \"Sobel(Y) Luminosity\"))\n",
    "\n",
    "    sobel_r = sobel_threshold(r, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_s = sobel_threshold(s, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_l = sobel_threshold(l, orient='x', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_r = perspective_transform(sobel_r, viewport=viewport, offset=offset, reverse=False)\n",
    "    sobel_s = perspective_transform(sobel_s, viewport=viewport, offset=offset, reverse=False)\n",
    "    sobel_l = perspective_transform(sobel_l, viewport=viewport, offset=offset, reverse=False)\n",
    "    show_grid((sobel_r,sobel_s,sobel_l), (\"Sobel(X) Red\", \"Sobel(X) Saturation\", \"Sobel(X) Luminosity\"))\n",
    "\n",
    "    sobel_r = sobel_threshold(r, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_s = sobel_threshold(s, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_l = sobel_threshold(l, orient='both', sobel_kernel=sobel_kernel, thresh=sobel_thresh)\n",
    "    sobel_r = perspective_transform(sobel_r, viewport=viewport, offset=offset, reverse=False)\n",
    "    sobel_s = perspective_transform(sobel_s, viewport=viewport, offset=offset, reverse=False)\n",
    "    sobel_l = perspective_transform(sobel_l, viewport=viewport, offset=offset, reverse=False)\n",
    "    show_grid((sobel_r,sobel_s,sobel_l), (\"Sobel(Both) Red\", \"Sobel(Both) Saturation\", \"Sobel(Both) Luminosity\"))\n",
    "\n",
    "grad_r = gradient_threshold(r, sobel_kernel=sobel_kernel, thresh=gradient_thresh)\n",
    "grad_l = gradient_threshold(l, sobel_kernel=sobel_kernel, thresh=gradient_thresh)\n",
    "grad_s = gradient_threshold(s, sobel_kernel=sobel_kernel, thresh=gradient_thresh)\n",
    "show_grid((grad_r,grad_s,grad_l), (\"Gradient Red\", \"Gradient Saturation\", \"Gradient Luminosity\"))\n",
    "\n",
    "sg_r = sobel_and_gradient(r, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "sg_l = sobel_and_gradient(l, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "sg_s = sobel_and_gradient(s, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "\n",
    "sg_r = perspective_transform(sg_r, viewport=viewport, offset=offset, reverse=False)\n",
    "sg_l = perspective_transform(sg_l, viewport=viewport, offset=offset, reverse=False)\n",
    "sg_s = perspective_transform(sg_s, viewport=viewport, offset=offset, reverse=False)\n",
    "show_grid((sg_r,sg_s,sg_l), (\"Sobel & Gradient Red\", \"Sobel & Gradient Saturation\", \"Sobel & Gradient Luminosity\"))\n",
    "\n",
    "t_r = sobel_LR_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150))\n",
    "t_l = sobel_LR_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150))\n",
    "t_s = sobel_LR_threshold(image, sobel_kernel=15, sobel_thresh=(30, 150))\n",
    "t_r = perspective_transform(t_r, viewport=viewport, offset=offset, reverse=False)\n",
    "t_l = perspective_transform(t_l, viewport=viewport, offset=offset, reverse=False)\n",
    "t_s = perspective_transform(t_s, viewport=viewport, offset=offset, reverse=False)\n",
    "show_grid((t_r, t_s, t_l), (\"Threshold Red\", \"Threshold Saturation\", \"Threshold Luminosity\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_width = 100\n",
    "window = np.ones(window_width)\n",
    "l_sum = np.sum(sg_s[int(3*h/4):,:int(w/2)], axis=0)\n",
    "r_sum = np.sum(sg_s[int(3*h/4):,int(w/2):], axis=0)\n",
    "l_sum = np.sum(sg_s[int(3*h/4):,:], axis=0)\n",
    "show_grid((sg_s[int(3*h/4):,:int(w/2)], sg_s[int(3*h/4):,int(w/2):]), (\"Left\", \"Right\"))\n",
    "l_conv_signal = np.convolve(window, l_sum)\n",
    "\n",
    "#what pixels are non zero in the convolution signal\n",
    "indicies = np.arange(len(l_conv_signal))\n",
    "idx_list = np.extract((l_conv_signal > 0) , indicies)\n",
    "print(len(idx_list), len(l_conv_signal))\n",
    "plt.figure()\n",
    "plt.hist(idx_list, normed=False, alpha=0.2, bins=739)\n",
    "print(\"Dirty\",np.std(idx_list))\n",
    "\n",
    "l_sum = np.sum(t_s[int(3*h/4):,:int(w/2)], axis=0)\n",
    "r_sum = np.sum(t_s[int(3*h/4):,int(w/2):], axis=0)\n",
    "l_sum = np.sum(t_s[int(3*h/4):,:], axis=0)\n",
    "show_grid((t_s[int(3*h/4):,:], t_s[int(3*h/4):,:]), (\"Left\", \"Right\"))\n",
    "l_conv_signal = np.convolve(window, l_sum)\n",
    "\n",
    "indicies = np.arange(len(l_conv_signal))\n",
    "#condition = np.logical_and(l_conv_signal > 0, labels < value+scale)\n",
    "idx_list = np.extract((l_conv_signal > 0) , indicies)\n",
    "print(len(idx_list), len(l_conv_signal))\n",
    "plt.figure()\n",
    "q = plt.hist(idx_list, normed=False, alpha=0.2, bins=739)\n",
    "print(\"clean \",np.std(idx_list))\n",
    "#show_grid((l_sum,l_conv_signal), (\"Sum\",\"Convolution\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from CameraOperations import show_grid, sobel_and_gradient\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "sobel_thresh=(30, 150)\n",
    "gradient_thresh=(0.7, 1.3)\n",
    "sobel_kernel=9\n",
    "\n",
    "#img = mpimg.imread(\"corrected_images/adj_test4.jpg\")\n",
    "img = mpimg.imread(\"corrected_images/adj_straight_lines1.jpg\")\n",
    "r = img[:,:,0]\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "s = hls[:,:,2]\n",
    "l = hls[:,:,1]\n",
    "hls[:,:,0] = 0\n",
    "\n",
    "s = sobel_and_gradient(s, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "l = sobel_and_gradient(l, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "hls = sobel_and_gradient(hls, sobel_kernel=sobel_kernel, sobel_thresh=sobel_thresh, gradient_thresh=gradient_thresh)\n",
    "\n",
    "combined = np.zeros_like(s).astype(\"uint8\")\n",
    "combined[((s == 1) | (l == 1))] = 1\n",
    "\n",
    "s = cv2.cvtColor(s.astype(\"uint8\"), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "s = perspective_transform(255*s, viewport=viewport, offset=80, reverse=False)\n",
    "l = perspective_transform(255*l, viewport=viewport, offset=80, reverse=False)\n",
    "c = perspective_transform(255*combined, viewport=viewport, offset=80, reverse=False)\n",
    "hls = perspective_transform(255*hls, viewport=viewport, offset=80, reverse=False)\n",
    "\n",
    "show_grid((s, l, c, hls), (\"s\", \"l\", \"combined\", \"LS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from LaneLines import Road\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from CameraOperations import show_grid, sobel_LS_threshold\n",
    "%matplotlib inline\n",
    "\n",
    "sobel_thresh=(30, 150)\n",
    "gradient_thresh=(0.7, 1.3)\n",
    "sobel_kernel=9\n",
    "\n",
    "road = Road(window_height=48, window_width=100, margin=50, w=1280, h=720)\n",
    "#image = mpimg.imread(\"corrected_images/adj_test5.jpg\")\n",
    "#image = mpimg.imread(\"corrected_images/adj_straight_lines1.jpg\")\n",
    "image = mpimg.imread(\"debug_images/1260.jpg\")\n",
    "\n",
    "img_thres = road.image_threshold(image)\n",
    "warped = road.perspective_transform(img_thres)\n",
    "warped_orig = road.perspective_transform(image)\n",
    "road.parse_image(image)\n",
    "road.sobel_kernel=15\n",
    "overlay, mapped_lanes = road.draw_overlay(image, warped)\n",
    "show_grid((image, img_thres, overlay), (\"Original\", \"Thresholded\", \"overlay\"))\n",
    "show_grid((warped_orig, warped, mapped_lanes), (\"Original\", \"Thresholded\", \"Mapped Lanes\"))\n",
    "print(road.viewport)\n",
    "print(\"Left\",road.left_lane)\n",
    "print(\"Right\", road.right_lane)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_grid((warped_orig, warped), (\"Original\", \"Thresholded\"), ticks=(40,40))\n",
    "show_grid((image, overlay), (\"Original\", \"Overlay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c62da8d84e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mclip_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./marked_v9_challenge_video.mp4\"\u001b[0m \u001b[1;31m#\"marked_v6_challenge_video.mp4\" #\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mclip_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"challenge_video.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mimg_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_frame_lane_markings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time img_clip.write_videofile(clip_output, audio=False)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \"\"\"\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-179>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[1;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \"\"\"\n\u001b[1;32m    653\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-136>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \"\"\"\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5c62da8d84e5>\u001b[0m in \u001b[0;36mmake_frame_lane_markings\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mun_dst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrect_distortion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mwarped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mun_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlane_markings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapped_lanes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_overlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mun_dst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"debug_images/challenge/{0}_overlay.jpg\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlane_markings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Users\\joely\\Documents\\Udacity\\CarND-Advanced-Lane-Lines\\LaneLines.py\u001b[0m in \u001b[0;36mdraw_overlay\u001b[0;34m(self, image, warped)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_overlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0ml_pts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_lane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mr_pts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_lane\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Users\\joely\\Documents\\Udacity\\CarND-Advanced-Lane-Lines\\LaneLines.py\u001b[0m in \u001b[0;36mfit_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mcoeff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[1;31m#y = np.array([p for p in range(0,h+1,10)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoeff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcoeff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcoeff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mpts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from CameraOperations import correct_distortion\n",
    "from LaneLines import Road\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "with open(\"./camera_parameters.p\", mode='rb') as f:\n",
    "    camera_params = pickle.load(f)\n",
    "global_dist = camera_params['dist']\n",
    "global_mtx = camera_params['mtx']\n",
    "\n",
    "\n",
    "idx=0\n",
    "cache = None\n",
    "road = Road(window_height=80, window_width=100, margin=100, w=1280, h=720)\n",
    "def make_frame_lane_markings(image):\n",
    "    global idx\n",
    "    global cache\n",
    "    DEBUG = True\n",
    "    un_dst = correct_distortion(image, global_mtx, global_dist)\n",
    "    warped = road.parse_image(un_dst)\n",
    "    lane_markings, mapped_lanes = road.draw_overlay(un_dst, warped)\n",
    "    if DEBUG:\n",
    "        mpimg.imsave(\"debug_images/challenge/{0}_overlay.jpg\".format(idx), lane_markings)\n",
    "        mpimg.imsave(\"debug_images/challenge/{0}_mapped_lanes.jpg\".format(idx), mapped_lanes)\n",
    "        mpimg.imsave(\"debug_images/challenge/{0}.jpg\".format(idx), un_dst)\n",
    "    idx = idx + 1\n",
    "    return lane_markings\n",
    "\n",
    "clip_output = \"./marked_v9_challenge_video.mp4\" #\"marked_v6_challenge_video.mp4\" # \n",
    "clip_handle = VideoFileClip(\"challenge_video.mp4\", audio=False)\n",
    "img_clip = clip_handle.fl_image(make_frame_lane_markings) \n",
    "%time img_clip.write_videofile(clip_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
